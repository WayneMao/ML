@[TOC](目录)

### 前言

特征选择是一个重要的“数据预处理”过程，在实现机器学习任务中，获得数据后通常先进行特征选择，此后再训练学习器。[1]

特征选择的两大主要原因：

- **维数灾难问题**[2]。因为属性或者特征过多造成的问题，如果可以从中选择出重要的特征，使得后续学习过程仅需在一部分特征上构建模型，可以大大减轻维数灾难问题。从这个意义上讲，**特征选择**和**降维**技术有相似的动机，事实上它们也是**处理高维数据的两大主流技术**。
- **去除无关特征可以降低学习任务的难度，也同样让模型变得简单，降低计算复杂度**。

知道不同特征之间、特征与target的相关性，可以帮助我们进行特征选择。

相关代码:[GitHub]( https://github.com/WayneMao/ML/blob/master/Heatmap/相关性系数和热力图.ipynb )

### 1. 皮尔逊相关系数

在统计学中，**皮尔逊积矩相关系数**[3]（英语：Pearson product-moment correlation coefficient，又称作 **PPMCC**或**PCCs**， 文章中常用r或Pearson's r表示）用于度量两个变量X和Y之间的相关程度（线性相关），其值介于-1与1之间。在自然科学领域中，该系数广泛用于度量两个变量之间的线性相关程度。

在此之前，首先需要理解**协方差**（Covariance）, **协方差**在概率论和统计学中用于衡量两个变量的总体误差。协方差计算公式如下所示，[方差](https://zh.wikipedia.org/wiki/方差)是协方差的一种特殊情况，即当两个变量是相同的情况。


$$
\large COV(X,Y) = \frac {1}{n-1} \sum_1^n (X_i- \bar X)(Y_i-\bar Y)
$$

当两个变量相同时，协方差公式变为如下，这就是我们所熟知的方差。

$$COV(X,X) = E[(x - \mu)^2] = \frac{1}{n-1} \sum(X_i - X)^2$$

协方差表示的是两个变量的总体的误差，这与只表示一个变量误差的方差不同。 



两个变量之间的**皮尔逊相关系数**定义为两个变量之间的[协方差](https://zh.wikipedia.org/wiki/协方差)和[标准差](https://zh.wikipedia.org/wiki/标准差)的商：
$$
\rho _{X,Y}={\mathrm {cov} (X,Y) \over \sigma _{X}\sigma _{Y}}={E[(X-\mu _{X})(Y-\mu _{Y})] \over \sigma _{X}\sigma _{Y}}
$$

Pearson相关系数的具体公式如下：

$$
{\displaystyle r={\frac {\sum \limits _{i=1}^{n}(X_{i}-{\overline {X}})(Y_{i}-{\overline {Y}})}{{\sqrt {\sum \limits _{i=1}^{n}(X_{i}-{\overline {X}})^{2}}}{\sqrt {\sum \limits _{i=1}^{n}(Y_{i}-{\overline {Y}})^{2}}}}}}
$$

虽然以上两者都能反应两个随机变量的相关程度，但是与协方差相比，相关系数一个很大的优点是消除了量纲的影响。协方差在数值上受到量纲的影响很大，$X,Y$ 中任一者相对另外一者特别大的时候，都能对结果产生相当大的影响。当	$X,Y$这两个变量的方差都不为0时，上述公式(相关性系数)具有意义，相关性系数的取值范围在[-1,1]。



### 2. 热力图(haetmap)

 利用热力图可以看数据表里多个特征两两的相似度 。主要参考[seaborn.heatmap]( https://seaborn.pydata.org/generated/seaborn.heatmap.html )来画热力图。

具体的代码参见:[GitHub]( https://github.com/WayneMao/ML/blob/master/Heatmap/相关性系数和热力图.ipynb )





### 注：

1.  我们通常所说的方差有两种，一种是样本方差，一种是总体方差。当求样本方差的时候，分母是n-1，这样得到的是**无偏估计**；当求总体方差的时候，分母是n。 


### Reference：

[1] 周志华. 机器学习[M]. Qing hua da xue chu ban she, 2016. (第11章 特征选择与稀疏学习)

[2] 维基百科编者. 维数灾难[G/OL]. 维基百科, 2018(20180411)[2018-04-11]. [https://zh.wikipedia.org/w/index.php?title=%E7%BB%B4%E6%95%B0%E7%81%BE%E9%9A%BE&oldid=49101931](https://zh.wikipedia.org/w/index.php?title=维数灾难&oldid=49101931).

[3] 维基百科编者. 皮尔逊积矩相关系数[G/OL]. 维基百科, 2019(20191022)[2019-10-22]. [https://zh.wikipedia.org/w/index.php?title=%E7%9A%AE%E5%B0%94%E9%80%8A%E7%A7%AF%E7%9F%A9%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0&oldid=56568178](https://zh.wikipedia.org/w/index.php?title=皮尔逊积矩相关系数&oldid=56568178).

[4] https://blog.csdn.net/cymy001/article/details/79576019

[5]  https://www.jianshu.com/p/39220c7ac8e9 

[6] [彻底理解样本方差为何除以n-1]( https://blog.csdn.net/Hearthougan/article/details/77859173 )



