{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 朴素贝叶斯：文本分类永恒的经典\n",
    "### 9.1 理解朴素贝叶斯\n",
    "\n",
    "朴素贝叶斯，在文本分类上它是一个非常靠谱的基准(baseline)。  \n",
    "朴素贝叶斯-核心思想：统计单词在不同类别中出现的概率，然后根据这些结果进一步判断一个文本它于不同类别的概率。  \n",
    "贝叶斯定理：  \n",
    "$$p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$$  \n",
    "- p(y|x) 后验概率 posterior\n",
    "- p(x|y) 似然(likelihood)\n",
    "- p(y) 先验概率(prior)\n",
    "- p(x) Normalization\n",
    "\n",
    "条件独立的假设 计算 联合概率   \n",
    "条件独立(conditional independence)的假设，是为什么我们把朴素贝叶斯说成“朴素”的主要的原因。  \n",
    "\n",
    "注意：朴素贝叶斯法和贝叶斯估计是不同的概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "潜在风险：比如其中一个概率等于0， 那不管其他概率值是多少，最后的结果一定会等于0。  \n",
    "处理方法：平滑处理。   \n",
    "常用的方法- 加1平滑 add-one smoothing：\n",
    "$$p(w|y=c) = \\frac{类别为C的语料库中单词w出现的次数 + 1}{类别为C的语料库中包含的所有单词的个数 + v}$$\n",
    "v为词典的大小，即出现单词的种类。  \n",
    "\n",
    "例如：垃圾邮件分类。\n",
    "\n",
    "常见的分布模型：高斯分布(Gaussian naive Bayes)、多项分布(Multinomial naive Bayes)、伯努利分布(Bernoulli naive Bayes)等."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据中的样本个数： 4457 测试数据中的样本个数： 1115\n",
      "Accurancy on test data: 0.97847533632287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[956,  14],\n",
       "       [ 10, 135]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as malb\n",
    "\n",
    "# read data\n",
    "df = pd.read_csv('spam.csv',encoding = 'latin')# ,error_bad_lines=False\n",
    "df.head()\n",
    "\n",
    "# rename v1,v2 ,使得拥有更好的可读性\n",
    "df.rename(columns={'v1':'Label','v2':'Text'},inplace=True) # 是否返回一个新的DataFrame。如果为真，则忽略copy的值。\n",
    "df.head()\n",
    "\n",
    "# 把 ham spam  one-hot\n",
    "df['numLabel'] = df['Label'].map({'ham':0,'spam':1})\n",
    "df.head()\n",
    "\n",
    "# 统计有多少个ham,有多少个spam\n",
    "# print(\"The number of ham:\",len(df[df.numLabel == 0]),\"The number of spam:\",len(df[df.numLabel == 1]))\n",
    "# print(\"The number of total simples:\",len(df)) \n",
    "\n",
    "# 统计文本长度信息 并画出 histogram\n",
    "# text_lengths = [len(df.loc[i,'Text']) for i in range(len(df))] # df.loc[i,'Text']选取标签为Text的列\n",
    "# plt.hist(text_lengths,200,facecolor='blue',alpha=0.5)\n",
    "# plt.xlim([0,200])\n",
    "# plt.show()\n",
    "\n",
    "#导入英文的停用词库\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# CountVectorizer 类会将文本中的词语转换为词频矩阵\n",
    "\n",
    "# 构建文本的向量（基于词频的表示）\n",
    "vectorizer = CountVectorizer() # 创建词袋数据结构\n",
    "X = vectorizer.fit_transform(df.Text) # fit_transform函数计算各个词语出现的次数。\n",
    "y = df.numLabel\n",
    "\n",
    "# 将数据分成训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=100)\n",
    "print(\"训练数据中的样本个数：\",X_train.shape[0],\"测试数据中的样本个数：\",X_test.shape[0])\n",
    "\n",
    "# 利用朴素贝叶斯做训练\n",
    "from sklearn.naive_bayes import MultinomialNB # 先验为多项式分布的朴素贝叶斯\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = MultinomialNB(alpha=1.0,fit_prior=True)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accurancy on test data:\",accuracy_score(y_test,y_pred))\n",
    "\n",
    "# 打印混淆矩阵\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred, labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](Naive_bayes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 最大似然以及参数估计\n",
    "- 无条件优化\n",
    "- 带约束条件的优化\n",
    "\n",
    "**拉格朗日乘数法（Lagrange multiplier）**   \n",
    "传统几何方法，现在使用拉格朗日乘数法\n",
    "![image.png](Lagrange_multiplier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造朴素贝叶斯目标函数己求出最优解\n",
    "#### 1. 构造朴素贝叶斯的最大似然估计\n",
    "$$D{(x_1,y_1),(x_2,y_2),(x_3,y_3)\\dots (x_n,y_n)}$$\n",
    "$x特征,y标签$  x可能是离散型，也可能是连续型。文本每一个特征是单词可以认为这些特都是**离散型**的。  \n",
    "$$argmax\\ p(D) = argmax\\ \\prod_{i=1}^{n} p(x_i,y_i) = argmax\\ \\prod_{i=1}^{n} p(y_i)p(x_i|y_i)$$\n",
    "独立分布概率 --> 联合分布概率 ;$p(y_i)$每个类别的先验概率  \n",
    "\n",
    "判别模型 生成模型  \n",
    "\n",
    "首先，构建一个**词库**。文本-->向量；每个向量的大小 == 词库的大小。   \n",
    "因为$p(x_1|y_1) = \\prod_{j=1}^{v} p(w_j|y_1)^{x_{1j}}$ ,其中n为样本数，V为词库大小。  \n",
    "So,$$argmax\\ \\prod_{i=1}^{n} p(y_i)p(x_i|y_i) = argmax\\ \\prod_{i=1}^{n} p(y_i) \\prod_{j=1}^{v} p(w_j|y_i)^{x_{ij}}$$  \n",
    "\n",
    "在argmax的时候加log不改变优化目标。\n",
    "\n",
    "#### 2. 优化： 。。。。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 高斯朴素贝叶斯\n",
    "连续型特征： 比如一个人的身高值、温度、年龄。  \n",
    "如果特征是连续型的，我们则可以使用高斯分布来描述此条件概率。  \n",
    "- 高斯分布具有很多优点，比如在计算层面上有很多漂亮的特点(两个高斯分布相加/乘积是高斯分布，两个高斯分布的条件概率也是高斯分布等等)，这些特点会让计算变得尤其简单。  \n",
    "- 高斯分布特别适合表示真实的世界。其中最经典的定理叫作**中心极限定理**：只要我们观测到足够多的数据，那这些数据会服从高斯分布。  \n",
    "  \n",
    "针对一个特征在某一个类别(y=0,1,...)中的概率。利用某个类别下某个特征的所有连续型数据来拟合一个高斯分布，再去预测。   \n",
    "\n",
    "实际的工作当中，如果数据中有大量的连续型特征，我们其实是不会使用朴素贝叶斯模型的，而是使用逻辑回归、XGBoost等模型。   \n",
    "总结起来，朴素贝叶斯本身**最适合解决文本分类问题**。所以之后遇到任何一个只要跟文本相关的问题，可以尝试使用朴素贝叶斯来解决，至少它可以作为很靠谱的基准。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 补充说明高斯分布\n",
    "$$X\\sim N(\\mu,\\sigma^2)$$  \n",
    "其中$\\mu期望；\\sigma^2 方差$。\n",
    "\n",
    "则其概率密度函数为:\n",
    "\n",
    "$$f(x) = {1 \\over \\sigma\\sqrt{2\\pi} }\\,e^{- {{(x-\\mu )^2 \\over 2\\sigma^2}}}$$\n",
    "\n",
    "\n",
    "Reference:  \n",
    "推荐一本书[《正态分布的前世今生》](http://wise.xmu.edu.cn/_data/2016/07/28/c6a3daf3_e3c2_49e3_9aad_bf95fa4446bf/%E6%AD%A3%E5%A4%AA%E5%88%86%E5%B8%83%20final.pdf)   \n",
    "wikipedia:[正态分布](https://zh.wikipedia.org/wiki/正态分布)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 生成模型与判别模型\n",
    "**生成模型:** 顾名思义，生成模型是可以用来生成样本的！  \n",
    "例如：**GAN**，让机器写程序，让机器学会画画，让机器给自己编一个曲子，这就是生成模型可以做的事情。  \n",
    "\n",
    "**判别模型:** 主要用来判断样本的类别。\n",
    "\n",
    "| 生成模型       | 判别模型     |\n",
    "| -------------- | ------------ |\n",
    "| 朴素贝叶斯     | 逻辑回归     |\n",
    "| 隐马尔科夫模型 | 支持向量机   |\n",
    "| 高斯混合模型   | 条件随意场   |\n",
    "| 主题模型       | 卷积神经网络 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
